{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ET_Retrieval_Loop_Ls5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mIKI0mwwBnmQ",
        "AEekWlMpA_7-",
        "h98_ixFm-b6v",
        "z39LLWJs-R0l",
        "ySlEC_EeBQas",
        "j5eYImYu-Wsa",
        "1ZKEeHP6-MZa",
        "STqp3S9q-GsM",
        "jGjqh8ltBcTy",
        "T3gF6N-VANBC",
        "DyOogVDNAVSz",
        "YF8qRMgeAjqf",
        "19tx7fsBA12e"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReaganJHarris/ET_Retrieval/blob/main/ET_Retrieval_Loop_Ls5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIKI0mwwBnmQ"
      },
      "source": [
        "# Libraries and authorizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMNj-Qz6LLvW"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "from time import strftime, strptime, gmtime\n",
        "import math\n",
        "import pprint\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgNIuBasgydb",
        "outputId": "3ad2f184-4272-4257-f1fc-7f32d1975d40"
      },
      "source": [
        "#@title Install Earthengine Python API\n",
        "\n",
        "!pip install 'pyOpenSSL>=0.11'\n",
        "!pip install earthengine-api"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyOpenSSL>=0.11\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting cryptography>=3.3\n",
            "  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 23.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.11) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->pyOpenSSL>=0.11) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->pyOpenSSL>=0.11) (2.21)\n",
            "Installing collected packages: cryptography, pyOpenSSL\n",
            "Successfully installed cryptography-36.0.0 pyOpenSSL-21.0.0\n",
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.7/dist-packages (0.1.290)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from earthengine-api) (0.0.4)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from earthengine-api) (1.18.1)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from earthengine-api) (1.12.8)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from earthengine-api) (1.35.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from earthengine-api) (0.16.0)\n",
            "Requirement already satisfied: httplib2shim in /usr/local/lib/python3.7/dist-packages (from earthengine-api) (0.0.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from earthengine-api) (0.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from earthengine-api) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.12.1->earthengine-api) (1.26.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.12.1->earthengine-api) (3.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (21.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->earthengine-api) (0.2.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (3.0.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (1.24.3)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->earthengine-api) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->earthengine-api) (1.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQp9SDiRhVBC",
        "outputId": "c8e7b333-52dc-4fa5-a46d-1bbc59cc8b1f"
      },
      "source": [
        "#@title authenticate and initialize the Earthengine API\n",
        "!earthengine authenticate\n",
        "\n",
        "import ee\n",
        "ee.Initialize()\n",
        "\n",
        "image = ee.Image('srtm90_v4')\n",
        "print(image.getInfo())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=_pku8AFfNKfBYsBoJyqKbGy2eCcOWQa-T4uE6a_FjKc&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AX4XfWi7BdUBKd8Z4MuQSeC92AjFciZ2iS9CCUa5meM8mZjIAQXzReiOKZM\n",
            "\n",
            "Successfully saved authorization token.\n",
            "{'type': 'Image', 'bands': [{'id': 'elevation', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': -32768, 'max': 32767}, 'dimensions': [432000, 144000], 'crs': 'EPSG:4326', 'crs_transform': [0.000833333333333, 0, -180, 0, -0.000833333333333, 60]}], 'version': 1494271934303000.0, 'id': 'srtm90_v4', 'properties': {'system:time_start': 950227200000, 'system:time_end': 951177600000, 'system:asset_size': 18827626666}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp1SfPdW1p8_",
        "outputId": "4aed439f-6e04-47c9-e4b3-6e783d906339"
      },
      "source": [
        "#@title mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u36Cts7X1yiN"
      },
      "source": [
        "#@title authorize Google Drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEekWlMpA_7-"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h98_ixFm-b6v"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqpNIBqFk3eb"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "Counties = ee.FeatureCollection(\"TIGER/2018/Counties\")\n",
        "DayMET = ee.ImageCollection(\"NASA/ORNL/DAYMET_V3\")\n",
        "SRTM = ee.Image(\"USGS/SRTMGL1_003\")\n",
        "MODIS = ee.ImageCollection(\"MODIS/006/MOD11A2\")\n",
        "GLDAS = ee.ImageCollection(\"NASA/GLDAS/V021/NOAH/G025/T3H\")\n",
        "ARD_LST_5 = ee.ImageCollection('projects/ColoradoView/Landsat/ARD/5')\n",
        "MODIS_Albedo = ee.ImageCollection(\"MODIS/006/MCD43A3\")\n",
        "ERA5 = ee.ImageCollection(\"ECMWF/ERA5/DAILY\")\n",
        "GRIDMET = ee.ImageCollection(\"IDAHO_EPSCOR/GRIDMET\")\n",
        "ARD_ET_5 = ee.ImageCollection('projects/ColoradoView/Landsat/ARD_ET/5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z39LLWJs-R0l"
      },
      "source": [
        "## ARD Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2tZZ3VMdW3O"
      },
      "source": [
        "#@title Mask fuctions\n",
        "def maskLandsatARD(image):\n",
        "    fillBitMask = 1\n",
        "    clearBitMask = 1 << 1\n",
        "    cloudBitMask = 1 << 5\n",
        "  \n",
        "    lst_name = 'b1'\n",
        "    pixelqa_name = 'b2'\n",
        "    lstqa_name = 'b3'\n",
        "    lstqa_scale_name = 'STQA_scale_factor'\n",
        "  \n",
        "    lstqa_threshold = 5.0\n",
        "  \n",
        "    # get the pixel QA band\n",
        "    # pixelqa_name: 'b2'\n",
        "    pixelqa = image.select(pixelqa_name)\n",
        "  \n",
        "    # get the STQA band\n",
        "    lstqa = image.select(lstqa_name)\n",
        "    stqa_scale = ee.Number(image.get(lstqa_scale_name))\n",
        "    \n",
        "    mask = pixelqa.bitwiseAnd(fillBitMask).eq(0) \\\n",
        "      .And(pixelqa.bitwiseAnd(clearBitMask).neq(0)) \\\n",
        "      .And(pixelqa.bitwiseAnd(cloudBitMask).eq(0)) \\\n",
        "      .And(lstqa.multiply(stqa_scale).lt(lstqa_threshold))\n",
        "        \n",
        "    #.and(pixelqa.bitwiseAnd(cloudConfBit7Mask).eq(0))\n",
        "    #.and(pixelqa.bitwiseAnd(cirrusConfBit9Mask).eq(0))\n",
        "          \n",
        "          \n",
        "    # Return the masked image (excluding the PIXELQA and STQA layers)\n",
        "    return image.updateMask(mask) \\\n",
        "        .select(lst_name)  # [lst_name, pixelqa_name, lstqa_name]\n",
        "\n",
        "def toKelvin(image):\n",
        "    Celsius = image.get(['tmax', 'tmin'])\n",
        "    Kelvin = image.add(273)\n",
        "    return Kelvin\n",
        "\n",
        "def  maskAlb_swr(image):\n",
        "    QualityBitMask = 0 << 1\n",
        "    \n",
        "    pixelqa = image.select('BRDF_Albedo_Band_Mandatory_Quality_shortwave')\n",
        "    \n",
        "    \n",
        "    mask = pixelqa.bitwiseAnd(QualityBitMask).eq(0)\n",
        "          \n",
        "          \n",
        "    return image.updateMask(mask) \\\n",
        "        .select(['Albedo_BSA_shortwave']) \\\n",
        "        .multiply(0.001) \\\n",
        "        .addBands(mask.rename('mask'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySlEC_EeBQas"
      },
      "source": [
        "# Proccessing dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5eYImYu-Wsa"
      },
      "source": [
        "## Vaild Dates and c parameter function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjs1aUSzOLE1"
      },
      "source": [
        "# dates\n",
        "\n",
        "\n",
        "# for key, values in GEOID.items():\n",
        "#def FIPS_valid_dates(county):\n",
        "def parameter_fn(county_dict, TgtCounty_GEOID, start_date_str):\n",
        "\n",
        "  #start_date_str = '2017-01-01'\n",
        "  #end_date_str = '2017-12-31'\n",
        "\n",
        "  Date_st = ee.Date(start_date_str)\n",
        "  #Date_ed = ee.Date(end_date_str)\n",
        "  Date_ed = Date_st.advance(1, 'year')\n",
        "\n",
        "  date_range = Date_ed.difference(Date_st, 'day').getInfo()\n",
        "\n",
        "  # get the State boundary of Colorado\n",
        "  # TgtCounty_index = 0\n",
        "\n",
        "  #TgtCounty_GEOID = countyGEOID_array #[TgtCounty_index] #08123：\tWeld \n",
        "  # look up county name in the dict using the key (GEOID)\n",
        "  if (TgtCounty_GEOID in county_dict):\n",
        "    #TgtCounty_Name = countyName_array #[TgtCounty_index]\n",
        "    TgtCounty_Name = county_dict[TgtCounty_GEOID]\n",
        "  else:\n",
        "    # GEOID not found\n",
        "    raise ValueError(f\"Error: given GEOID {TgtCounty_GEOID} not found.\")\n",
        "\n",
        "\n",
        "  TgtCounty_Bnds = Counties.filter(ee.Filter.eq('GEOID', TgtCounty_GEOID))\n",
        "  # print(TgtCounty_Bnds)\n",
        "  # print(TgtCounty_Bnds.first().geometry().getInfo())\n",
        "  TgtCounty_Bnds_geom = TgtCounty_Bnds.first().geometry()\n",
        "  TgtCounty_centroid = TgtCounty_Bnds_geom.centroid()\n",
        "  \n",
        "  geom_State_Bnds_CO_geometries = TgtCounty_Bnds.first().geometry().getInfo()\n",
        "  # print(geom_State_Bnds_CO_geometries)\n",
        "  # if isinstance(geom_State_Bnds_CO_geometries, list):\n",
        "  if geom_State_Bnds_CO_geometries['type'] == 'GeometryCollection':\n",
        "    for igeom in geom_State_Bnds_CO_geometries['geometries']:\n",
        "      if igeom['type'] == 'Polygon' or igeom['type'] == 'MultiPolygon':\n",
        "        geom_State_Bnds_CO = igeom['coordinates']\n",
        "        break\n",
        "  else:\n",
        "    geom_State_Bnds_CO = geom_State_Bnds_CO_geometries['coordinates']\n",
        "\n",
        "  # print(geom_State_Bnds_CO)\n",
        "        \n",
        "        \n",
        "  # geom_State_Bnds_CO = TgtCounty_Bnds.first().geometry().getInfo()['coordinates'] \n",
        "  \n",
        "\n",
        "  geom_str = str(geom_State_Bnds_CO)\n",
        "                \n",
        "  total_count_TgtCounty_500 = ee.Image(1).clipToCollection(TgtCounty_Bnds).rename('count').reduceRegion( \\\n",
        "        reducer= ee.Reducer.count(), \\\n",
        "        geometry= TgtCounty_Bnds.first().geometry(), \\\n",
        "        scale= 500, \\\n",
        "        maxPixels= 1e13 \\\n",
        "      ).get('count')\n",
        "\n",
        "  ## valid dates function\n",
        "  date_range = Date_ed.difference(Date_st, 'day').getInfo();\n",
        "\n",
        "  # create list of dates from start through date range\n",
        "  days = ee.List.sequence(0, date_range, 1.0)\n",
        "  def generate_date_feature(d):\n",
        "  # date_Fts = days.map(function(d) {\n",
        "    #  d: the index of the continuous sequence (i.e., days)\n",
        "    #  cur_date: ee.Date of the day pointed by d\n",
        "    cur_date = Date_st.advance(d, 'day')\n",
        "    #  filter by the cur_date\n",
        "    cur_ImgCol = ARD_ET_5.filterDate(cur_date)\n",
        "    #  reduce resolution of the ImageCollection \n",
        "    # cur_ImgCol = cur_ImgCol.map(function(inImg){\n",
        "    def coarse_reproject(inImg):\n",
        "      # reproject in very low resolution (1920m) in order to reduce the calulation burdun.\n",
        "      return inImg.reproject('EPSG:3857', None, 500)\n",
        "    \n",
        "    cur_ImgCol = cur_ImgCol.map(coarse_reproject)\n",
        "    # mosaic ImageCollection and clip to the target boundary\n",
        "    cur_ImgMosaic = ee.Image(cur_ImgCol.mosaic()).clipToCollection(TgtCounty_Bnds)\n",
        "    # get the number of bands in the Image\n",
        "    num_bands = cur_ImgMosaic.bandNames().size()\n",
        "    # If number of bands > 0, return a normal date string, otherwise get an empty sting\n",
        "    cur_date_str = ee.Algorithms.If(num_bands.gt(0), cur_date.format('YYYY-MM-dd'), '')\n",
        "\n",
        "    cur_countMaskVal = ee.Algorithms.If(num_bands.gt(0), \n",
        "      cur_ImgMosaic.mask().clipToCollection(TgtCounty_Bnds).select(0).updateMask(cur_ImgMosaic.mask().select(0)).rename('count').reduceRegion( \n",
        "        reducer= ee.Reducer.count(), \n",
        "        geometry= TgtCounty_Bnds.first().geometry(), \n",
        "        scale= 500, \n",
        "        maxPixels= 1e13 \n",
        "      ).get('count'), \n",
        "      0)\n",
        "    \n",
        "    # create a empty Feature with two properties: date_str and date_str_len\n",
        "    ret_date_Ft = ee.Feature(None, { \n",
        "    'date_str': cur_date_str, \n",
        "    'date_str_len': ee.String(cur_date_str).length(), \n",
        "    'count': cur_countMaskVal})\n",
        "    return ret_date_Ft\n",
        "\n",
        "  date_Fts = days.map(generate_date_feature)\n",
        "  # print(\"date_Fts\", date_Fts)\n",
        "\n",
        "  # filter List of Features to exclude those invalid dates (i.e., date_str_len == 0)\n",
        "  valid_dates_filtered = date_Fts \\\n",
        "    .filter(ee.Filter.gt('date_str_len', 0)) \\\n",
        "    .filter(ee.Filter.gt('count', ee.Number(total_count_TgtCounty_500).multiply(0.5)))\n",
        "  # print(\"valid_dates_Fts\", valid_dates_filtered)\n",
        "\n",
        "  # convert the List of Features to List of Strings (i.e., list of date_str_len)\n",
        "  def features_to_string(inFt):\n",
        "    inFt = ee.Feature(inFt)\n",
        "    return inFt.get('date_str')\n",
        "\n",
        "  valid_dates_filtered_StringList = valid_dates_filtered.map(features_to_string)\n",
        "  # batch fetch List content to client\n",
        "  valid_dates = valid_dates_filtered_StringList.getInfo()\n",
        "  num_valid_dates = len(valid_dates)\n",
        "  print(num_valid_dates)\n",
        "  # print(\"valid_dates\", num_valid_dates, valid_dates)\n",
        "  #return valid_dates\n",
        "\n",
        "  #Define loop to derive c parameter via month in valid date\n",
        "\n",
        "  #Import dictionary(?)/text file with c parameters by month\n",
        "  #Moffat monthly averages in 2003\n",
        "  from datetime import datetime\n",
        "  # TODO use dataframe...\n",
        "  CO_cPara_DF = pd.read_pickle('/gdrive/MyDrive/Ls5_Elbert_cPara.pkl')\n",
        "  SeasonalCO_cPara1 = CO_cPara_DF.groupby(['Year','Season']).agg({'mean':['mean']}).reset_index()\n",
        "  # SeasonalCO_cPara.groupby('Season').agg({'mean mean': ['mean']}).reset_index()\n",
        "  SeasonalCO_cPara1.columns = [' '.join(col).strip() for col in SeasonalCO_cPara1.columns.values]\n",
        "  SeasonalCO_cPara = SeasonalCO_cPara1.groupby('Season').agg({'mean mean': ['mean']}).reset_index()\n",
        "  SeasonalCO_cPara.columns = [' '.join(col).strip() for col in SeasonalCO_cPara.columns.values]\n",
        "  SeasonalCO_cPara = SeasonalCO_cPara.rename(columns={'mean mean mean':'mean'})\n",
        "  SeasonalCO_cPara = SeasonalCO_cPara.set_index('Season')\n",
        "  Seasonal_cPara = SeasonalCO_cPara.to_dict('dict')\n",
        "\n",
        "  cPara_Arr = []\n",
        "\n",
        "  for x in valid_dates:\n",
        "    dt_conversion = datetime.strptime(x, '%Y-%m-%d')\n",
        "    month_date = dt_conversion.month\n",
        "    # if 1 <= month_date <= 3:\n",
        "    #   season = 'Winter'\n",
        "    #   cPara = Seasonal_cPara['mean'][season]\n",
        "    #   continue\n",
        "    if 3 < month_date <= 6:\n",
        "      season = 'Spring'\n",
        "      cPara = Seasonal_cPara['mean'][season]\n",
        "    elif 6 < month_date <= 9:\n",
        "      season = 'Summer'\n",
        "      cPara = Seasonal_cPara['mean'][season]\n",
        "    else:\n",
        "      season = 'Fall'  \n",
        "      cPara = Seasonal_cPara['mean'][season]\n",
        "      # print(cPara)\n",
        "      # print(type(cPara))\n",
        "    cPara_Arr.append(cPara)\n",
        "\n",
        "\n",
        "  return valid_dates, TgtCounty_Bnds, TgtCounty_Name, cPara_Arr\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZKEeHP6-MZa"
      },
      "source": [
        "# Potential ET function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sda5WZGXdpCX"
      },
      "source": [
        "# @title Potential ET function\n",
        "# Potential ET from FAO\n",
        "#def potential_ET_fn(in_date):\n",
        "def potential_ET_fn(in_date, TgtCounty_Bnds):\n",
        "# in_date = FIPS_valid_dates(GEOID)\n",
        "  Date_st = in_date\n",
        "  Date_ed = Date_st.advance(1,'day')\n",
        "\n",
        "  # Potential ET\n",
        "\n",
        "  ARD_Img = ee.Image(ARD_LST_5 \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd')) \\\n",
        "    .map(maskLandsatARD) \\\n",
        "    .mosaic() \\\n",
        "    )\n",
        "      \n",
        "  ARD_Img = ARD_Img.select(0).multiply(0.1).rename('LST')\n",
        "\n",
        "  #ARD mask for other image collections\n",
        "  ARD_Img_mask = ARD_Img.mask().clip(TgtCounty_Bnds)\n",
        "\n",
        "  # DayMET\n",
        "  DayMET_ImgCol = DayMET \\\n",
        "    .filterBounds(TgtCounty_Bnds) \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd')) \\\n",
        "    .select(['tmax', 'tmin', 'srad', 'dayl'])\n",
        "\n",
        "  DayMET_Img = ee.Image(DayMET_ImgCol \\\n",
        "    .map(toKelvin) \\\n",
        "    .mosaic()) \\\n",
        "    .clip(TgtCounty_Bnds) \\\n",
        "    .updateMask(ARD_Img_mask)\n",
        "\n",
        "  #Gridmet\n",
        "  GRIDMET_ImgCol = GRIDMET \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd')) \\\n",
        "    .filterBounds(TgtCounty_Bnds) \\\n",
        "    .select('eto', 'etr', 'vpd', 'vs', 'srad', 'rmax', 'rmin')\n",
        "    \n",
        "  GRIDMET_Img = ee.Image(GRIDMET_ImgCol \\\n",
        "    .mosaic()) \\\n",
        "    .clipToCollection(TgtCounty_Bnds)\n",
        "\n",
        "  #ERA5\n",
        "  ERA5_ImgCol = ERA5 \\\n",
        "    .filterBounds(TgtCounty_Bnds) \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd')) \\\n",
        "    .select(['u_component_of_wind_10m', 'v_component_of_wind_10m']) \n",
        "        \n",
        "  ERA5_Img = ee.Image(ERA5_ImgCol \\\n",
        "    .mosaic()) \\\n",
        "    .resample('bilinear') \\\n",
        "    .clipToCollection(TgtCounty_Bnds) \\\n",
        "    .updateMask(ARD_Img_mask)\n",
        "\n",
        "  # MODIS Albedo\n",
        "  MOD_Alb_ImgCol = MODIS_Albedo \\\n",
        "    .filterBounds(TgtCounty_Bnds) \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd'))\n",
        "\n",
        "  Alb_Img = ee.Image(MOD_Alb_ImgCol \\\n",
        "    .map(maskAlb_swr) \\\n",
        "    .mosaic()) \\\n",
        "    .resample('bilinear') \\\n",
        "    .clipToCollection(TgtCounty_Bnds) \\\n",
        "    .updateMask(ARD_Img_mask)\n",
        "\n",
        "  # GLDAS\n",
        "  # GLDAS_ImgCol = GLDAS \\\n",
        "  #   .filterBounds(TgtCounty_Bnds) \\\n",
        "  #   .filterDate(Date_st.advance(6, 'hours'), Date_ed.advance(6, 'hours')) \\\n",
        "  #   .select(['Swnet_tavg', 'PotEvap_tavg', 'Lwnet_tavg', 'SWdown_f_tavg'])\n",
        "      \n",
        "  # GLDAS_Img = GLDAS_ImgCol \\\n",
        "  #   .reduce(ee.Reducer.mean()) \\\n",
        "  #   .resample('bilinear') \\\n",
        "  #   .clipToCollection(TgtCounty_Bnds) \\\n",
        "  #   .updateMask(ARD_Img_mask)\n",
        "\n",
        "  #  Es minimum temp\n",
        "  # net_swr_Swnet = DayMET_Img.expression('((1-alb)*swr*day_seconds)/(1.0e6)', {\n",
        "  #   'swr': GRIDMET_Img.select('srad'),\n",
        "  #   'alb': Alb_Img.select('Albedo_BSA_shortwave'),\n",
        "  #   'day_seconds': 86400\n",
        "  # })  \\\n",
        "  #   .rename('Net_Daily_SWR');\n",
        "  SRTM_Img = SRTM \\\n",
        "    .select('elevation') \\\n",
        "    .clipToCollection(TgtCounty_Bnds) \\\n",
        "  \n",
        "  current_year = Date_st.get('year');\n",
        "  empty_date = ee.Date.fromYMD(current_year, 1, 1);\n",
        "  # print(empty_date);\n",
        "  DOY_st =  Date_st.difference(empty_date, 'day').add(1)\n",
        "  # print(DOY_st);\n",
        "  latitude = ee.Image.pixelLonLat().select('latitude').multiply(ee.Number(math.pi).divide(180));\n",
        "  # Map.addLayer(latitude, {}, 'Latitude');\n",
        "  earth_sun_Dist = DayMET_Img.expression('1 + 0.033 * cos((2 * pi)/365 * DOY)', {                                                      \n",
        "      'pi': math.pi,  \\\n",
        "      'DOY': DOY_st,  \\\n",
        "    });\n",
        "  # print(earth_sun_Dist);\n",
        "  solar_constant = 0.0820 \n",
        "  # MJ/m2/min\n",
        "  solar_decl = DayMET_Img.expression('0.409 * sin(2*pi/365 * DOY - 1.39)',  { \n",
        "      'pi': math.pi,  \\\n",
        "      'DOY': DOY_st,  \\\n",
        "    });\n",
        "  # print(delta);\n",
        "  # gamma = (latitude.tan().multiply(delta.tan()).multiply(-1)).acos();\n",
        "  # sunset_hr_angle = math.acos(math.tan(latitude) * (math.tan(delta)) * -1)\n",
        "  sunset_hr_angle = DayMET_Img.expression('acos(tan(latitude) * tan(delta) * -1)', {\n",
        "      'latitude': latitude, \\\n",
        "      'delta': solar_decl \\\n",
        "  })\n",
        "  extraterrestial_rad = DayMET_Img.expression(  \\\n",
        "      '((24 * 60) / pi) * Gsc * dr * (gamma * sin(latitude) * sin(delta) + cos(latitude) * cos(delta) * sin(gamma))', {\n",
        "          'pi': math.pi,  \\\n",
        "          'Gsc': solar_constant,  \\\n",
        "          'dr': earth_sun_Dist, \\\n",
        "          'gamma': sunset_hr_angle, \\\n",
        "          'latitude': latitude, \\\n",
        "          'delta': solar_decl, \\\n",
        "        });\n",
        "  # print(extraterrestial_rad.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100));\n",
        "\n",
        "  solar_rad = extraterrestial_rad.expression('(0.75 + 2 * 1.0e-5 * elev) * Rs', {\n",
        "      'elev': SRTM_Img, \\\n",
        "      'Rs': extraterrestial_rad \\\n",
        "    });\n",
        "\n",
        "  net_swr_Swnet = solar_rad.expression('(1-alb)*Rsa', {\n",
        "    'alb': Alb_Img.select('Albedo_BSA_shortwave'),  \\\n",
        "    'Rsa': solar_rad  \\\n",
        "  });\n",
        "\n",
        "  # print('Net shortwave rad Senay 2013 Eq. 8', net_swr_Swnet.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100));\n",
        "\n",
        "  # swr_mean = net_swr_Swnet.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('shortwave rad', swr_mean)\n",
        "\n",
        "  #  GRIDMET Actual Vapor Pressure\n",
        "  #  Es minimum temp\n",
        "  svp_min = DayMET_Img.expression('0.6108*(e**((17.27*tmin)/(tmin+237.3)))', {\n",
        "      'e': 2.71828,\n",
        "      'tmin': DayMET_Img.select('tmin').subtract(273.16)\n",
        "  }) \\\n",
        "    .rename('Saturated_Vapor_Pressure');\n",
        "\n",
        "  # svp_min_mean = svp_min.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('Sat_Vapor_Press_min_mean', svp_min_mean)\n",
        "\n",
        "  # Es Maximum Temp\n",
        "  svp_max = DayMET_Img.expression('0.6108*(e**((17.27*tmax)/(tmax+237.3)))', {\n",
        "    'e': 2.71828,\n",
        "    'tmax': DayMET_Img.select('tmax').subtract(273.15)\n",
        "  }) \\\n",
        "    .rename('Saturated_Vapor_Pressure')\n",
        "\n",
        "  # svp_max_mean = svp_max.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('Sat_Vapor_Press_max_mean', svp_max_mean);\n",
        "\n",
        "  # Actual Vapor Pressure from relative humidity\n",
        "  Ea = ((svp_min.multiply(GRIDMET_Img.select('rmax').divide(100)))\n",
        "    .add(svp_max.multiply(GRIDMET_Img.select('rmin').divide(100)))) \\\n",
        "    .divide(2) \\\n",
        "    .rename('Actual_Vapor_Pressure');\n",
        "\n",
        "  # AVP_mean = Ea.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('ActualVaporPressure_mean', AVP_mean)\n",
        "\n",
        "  # Net Long-wave Radiation\n",
        "  net_lwr = DayMET_Img.expression('(sigma*((tmin**4+tmax**4)/2))*(0.34-(0.14*Kpa))*(1.35*(Rs_Rso)-0.35)', { \\\n",
        "    'Rs_Rso': 1, \\\n",
        "    'sigma': 0.0000000049, \\\n",
        "    'tmin': DayMET_Img.select('tmin'), \\\n",
        "    'tmax': DayMET_Img.select('tmax'), \\\n",
        "    'Kpa': Ea.sqrt() \\\n",
        "  }) \\\n",
        "    .rename('Net_longwave_radiation')\n",
        "  # lwr_mean = net_lwr.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('longwave mean', lwr_mean)\n",
        "\n",
        "\n",
        "  # Calculating Rn = R_ns - R_nl\n",
        "  # This output is in MJ/m^2/d\n",
        "  ClearSky_Rn = net_swr_Swnet.subtract(net_lwr) \\\n",
        "    .rename('Clear_Sky_Net_Radiation')\n",
        "  # net_rad_mean = ClearSky_Rn.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('ClearSky net rad', net_rad_mean)\n",
        "\n",
        "  # AVP_mean = Ea.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100);\n",
        "  # print('ActualVaporPressure_mean', AVP_mean);\n",
        "\n",
        "  # Es average of saturated min and max VP\n",
        "  Es = (svp_min.add(svp_max)).divide(2).rename('saturated_vp')\n",
        "  # Es_mean = Es.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('Es mean', Es_mean)\n",
        "  # saturation vapor pressure deficit (VPD) (kPa)\n",
        "  Es_Ea = Es.subtract(Ea).rename('VPD')\n",
        "  # VPD_mean = Es_Ea.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('VPD_mean', VPD_mean)\n",
        "\n",
        "  # Delta is the Slope of the saturation vapor pressure curve [kPa/C] \n",
        "  # FAO Irrigation and Drainage Paper 56, (Page 37)\n",
        "  Tmin_C = DayMET_Img.select('tmin').subtract(273)\n",
        "  Tmax_C = DayMET_Img.select('tmax').subtract(273)\n",
        "  Tavg_C = (Tmax_C.add(Tmin_C)).divide(2).rename('Tavg')\n",
        "\n",
        "  delta = DayMET_Img.expression('(4098*(Es))/(T+237.3)**2', {\n",
        "    'Es': Es,\n",
        "    'T': Tavg_C,\n",
        "  }) \\\n",
        "    .rename('delta');\n",
        "  # delta_mean = delta.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('delta_mean', delta_mean)\n",
        "\n",
        "  # P = 101.3((293-0.0065*Z)/293)^5.25\n",
        "  # Z = elevation (m)\n",
        "  # SRTM_Img = SRTM \\\n",
        "  #   .select('elevation') \\\n",
        "  #   .clipToCollection(TgtCounty_Bnds) \\\n",
        "\n",
        "  # pressure\n",
        "  pressure = SRTM_Img.expression('101.3*((293-0.0065*SRTM_Img)/293)**5.25', { \\\n",
        "    'SRTM_Img': SRTM_Img \\\n",
        "  }) \\\n",
        "    .rename('Pressure')\n",
        "  # pressure_mean = pressure.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('pressure_mean', pressure_mean)\n",
        "\n",
        "  # psychrometric constant, Gamma \n",
        "  # Canstants for the equation:\n",
        "  lambda_1 = 2.45 # latent heat of vapoization (MJ/kg)\n",
        "  specific_heat = 1.013e-3 # specific heat at constant pressure (MJ/kg/C)\n",
        "  epsilon = 0.622 # ratio molecular weight of water vapour/dry air (unitless)\n",
        "  gamma = DayMET_Img.expression('(Cp*pressure)/(epsilon*lambda)', { \\\n",
        "    'Cp': specific_heat, \\\n",
        "    'pressure': pressure, \\\n",
        "    'epsilon': epsilon, \\\n",
        "    'lambda': lambda_1 \\\n",
        "  })\n",
        "  # gamma_mean = gamma.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('gamma mean', gamma_mean)\n",
        "\n",
        "  # Wind speed from ERA5\n",
        "  # sqrt(u^2+v^2)\n",
        "\n",
        "  # u wind is longitude\n",
        "  u_wind = ERA5_Img.select('u_component_of_wind_10m')\n",
        "\n",
        "  # v wind is latitude\n",
        "  v_wind = ERA5_Img.select('v_component_of_wind_10m')\n",
        "\n",
        "  # u2 wind speed sqrt(u^2+v^2)\n",
        "  # \n",
        "  wind_spd_10m = (u_wind.pow(2).add(v_wind.pow(2))).sqrt()\n",
        "\n",
        "  #mConverting 10m wind speed to 2m\n",
        "  # wind_conversion_facotr = 4.87 / ln(67.8 (10) - 5.42) = 0.75\n",
        "  wind_spd_2m = wind_spd_10m.multiply(0.75).rename('wind_speed_2m');\n",
        "  # wind_speed_mean = wind_spd_2m.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "  # print('wind_speed', wind_speed_mean)\n",
        "\n",
        "  # ETo equation\n",
        "  ETo = DayMET_Img.expression('(0.408*delta*(Rn-G)+gamma*(900/(T+273))*u2*(Es_Ea)) / (delta+gamma*(1+0.34*(u2)))', { \\\n",
        "      'delta': delta, \\\n",
        "      'Rn': ClearSky_Rn, \\\n",
        "      'G': 0, \\\n",
        "      'gamma': gamma, \\\n",
        "      'T': Tavg_C, \\\n",
        "      'u2': wind_spd_2m, \\\n",
        "      'Es_Ea': Es_Ea \\\n",
        "  })\n",
        "  # print(ETo.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100))\n",
        "  return ETo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STqp3S9q-GsM"
      },
      "source": [
        "# Actual ET Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUpnTO5BKbeH"
      },
      "source": [
        "#@title Actual ET function\n",
        "\n",
        "def Actual_ET_Fn(in_date, PET_value, TgtCounty_Bnds, cPara):\n",
        "  \n",
        "  Date_st = in_date\n",
        "  Date_ed = Date_st.advance(1,'day')\n",
        "\n",
        "  #  ARD LST Landsat \n",
        "  ARD_Img = ee.Image( \\\n",
        "    ARD_LST_5 \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd')) \\\n",
        "    .map(maskLandsatARD) \\\n",
        "    .mosaic() \\\n",
        "    )\n",
        "    \n",
        "  ARD_Img = ARD_Img.select(0).multiply(0.1).rename('LST')\n",
        "\n",
        "  ARD_Img_mask = ARD_Img.mask().clip(TgtCounty_Bnds)\n",
        "\n",
        "  # DayMET\n",
        "\n",
        "  DayMET_ImgCol = DayMET \\\n",
        "    .filterBounds(TgtCounty_Bnds) \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd')) \\\n",
        "    .select(['tmax', 'tmin', 'srad', 'dayl'])\n",
        "\n",
        "  DayMET_Img = ee.Image(DayMET_ImgCol \\\n",
        "    .map(toKelvin) \\\n",
        "    .mosaic()) \\\n",
        "    .clip(TgtCounty_Bnds) \\\n",
        "    .updateMask(ARD_Img_mask)\n",
        "\n",
        "  GRIDMET_ImgCol = GRIDMET \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd')) \\\n",
        "    .filterBounds(TgtCounty_Bnds) \\\n",
        "    .select('eto', 'etr', 'vpd', 'vs', 'srad', 'rmax', 'rmin')\n",
        "  \n",
        "  GRIDMET_Img = ee.Image(GRIDMET_ImgCol \\\n",
        "    .mosaic()) \\\n",
        "    .clipToCollection(TgtCounty_Bnds)\n",
        "\n",
        "  # c_coef = cPara\n",
        "  \n",
        "  # Cold Reference Pixel\n",
        "  Temp_Cold = DayMET_Img \\\n",
        "    .select('tmax') \\\n",
        "    .multiply(cPara) \\\n",
        "    .rename('Reference Cold Pixel')\n",
        "\n",
        "  Temp_min = DayMET_Img \\\n",
        "    .select('tmin') \n",
        "\n",
        "  Temp_mean = (DayMET_Img.select('tmax').add(Temp_min)).divide(2) \\\n",
        "    .rename('T_avg')\n",
        "  \n",
        "  # Calculate Air Density\n",
        "  Tkv = Temp_mean.multiply(1.01) \\\n",
        "    .rename('Virtual_Temperature')\n",
        "\n",
        "  SRTM_Img = SRTM.select('elevation') \\\n",
        "    .clipToCollection(TgtCounty_Bnds)\n",
        "\n",
        "  pressure = SRTM_Img.expression('101.3*((293-0.0065*SRTM_Img)/293)**5.25', { \\\n",
        "    'SRTM_Img': SRTM_Img \\\n",
        "  }) \\\n",
        "    .rename('Pressure')\n",
        "\n",
        "  Air_Density = pressure.expression('3.486*(pressure/Tkv)', { \\\n",
        "    'pressure': pressure, \\\n",
        "    'Tkv': Tkv \\\n",
        "  }) \\\n",
        "    .rename('Air_Density')\n",
        "  \n",
        "  # MODIS Albedo\n",
        "  MOD_Alb_ImgCol = MODIS_Albedo \\\n",
        "    .filterBounds(TgtCounty_Bnds) \\\n",
        "    .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd'))\n",
        "\n",
        "  Alb_Img = ee.Image(MOD_Alb_ImgCol \\\n",
        "    .map(maskAlb_swr) \\\n",
        "    .mosaic()) \\\n",
        "    .resample('bilinear') \\\n",
        "    .clipToCollection(TgtCounty_Bnds) \\\n",
        "    .updateMask(ARD_Img_mask)\n",
        "\n",
        "  # Shortwave radiation\n",
        "\n",
        "  # SW_down = DayMET_Img.select('SWdown_f_tavg_mean') \\\n",
        "  #   .multiply(86400)\n",
        "\n",
        "  # for srad from GRIDMET\n",
        "  # net_swr_Swnet = Alb_Img.expression('((1-alb)*swr*day_seconds)/(1.0e6)', {\n",
        "  #     'swr': GRIDMET_Img.select('srad'),\n",
        "  #     'alb': Alb_Img.select('Albedo_BSA_shortwave'),\n",
        "  #     'day_seconds': 86400\n",
        "  # }) \\\n",
        "  #   .rename('Net_Daily_SWR');\n",
        "\n",
        "  # ---Shortwave radiation from Senay 2013----\n",
        "  current_year = Date_st.get('year');\n",
        "  empty_date = ee.Date.fromYMD(current_year, 1, 1);\n",
        "  # print(empty_date);\n",
        "  DOY_st =  Date_st.difference(empty_date, 'day').add(1);\n",
        "  # print(DOY_st);\n",
        "  latitude = ee.Image.pixelLonLat().select('latitude').multiply(ee.Number(math.pi).divide(180));\n",
        "\n",
        "  earth_sun_Dist = ee.Number.expression('1 + 0.033 * cos((2 * pi)/365 * DOY)', {                                                           \n",
        "      'pi': math.pi,  \\\n",
        "      'DOY': DOY_st \\\n",
        "    });\n",
        "  # print(earth_sun_Dist);\n",
        "  solar_constant = 0.0820 \n",
        "  # MJ/m2/min\n",
        "  # Solar declination\n",
        "  solar_decl = DayMET_Img.expression('0.409 * sin(2*pi/365 * DOY - 1.39)',  {\n",
        "      'pi': math.pi,  \\\n",
        "      'DOY': DOY_st  \\\n",
        "    });\n",
        "  # print(delta);\n",
        "  # gamma = (latitude.tan().multiply(delta.tan()).multiply(-1)).acos();\n",
        "  # gamma = math.acos(math.tan(latitude) * (math.tan(delta)) * -1)\n",
        "\n",
        "  # sunset hour angle\n",
        "  sunset_hr_angle = DayMET_Img.expression('acos(tan(latitude) * tan(delta) * -1)', {\n",
        "      'latitude': latitude, \\\n",
        "      'delta': solar_decl \\\n",
        "  })\n",
        "\n",
        "  # extraterrestial radiation\n",
        "  extraterrestial_rad = DayMET_Img.expression(  \\\n",
        "      '((24 * 60) / pi) * Gsc * dr * (gamma * sin(latitude) * sin(delta) + cos(latitude) * cos(delta) * sin(gamma))', {\n",
        "          'pi': math.pi,  \\\n",
        "          'Gsc': solar_constant,  \\\n",
        "          'dr': earth_sun_Dist, \\\n",
        "          'gamma': sunset_hr_angle, \\\n",
        "          'latitude': latitude, \\\n",
        "          'delta': solar_decl, \\\n",
        "        });\n",
        "  # print(extraterrestial_rad.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100));\n",
        "\n",
        "  # Solar radiation\n",
        "  solar_rad = extraterrestial_rad.expression('(0.75 + 2 * 1.0e-5 * elev) * Rs', { \\\n",
        "      'elev': SRTM_Img, \\\n",
        "      'Rs': extraterrestial_rad \\\n",
        "    });\n",
        "\n",
        "  # net shortwave/solar radiation\n",
        "  net_swr_Swnet = solar_rad.expression('(1-alb)*Rsa', { \\\n",
        "    'alb': Alb_Img.select('Albedo_BSA_shortwave'),  \\\n",
        "    'Rsa': solar_rad  \\\n",
        "  });\n",
        "\n",
        "  # print('Net shortwave rad Senay 2013 Eq. 8', net_swr_Swnet.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100));\n",
        "\n",
        "  #  GRIDMET Actual Vapor Pressure\n",
        "  #  Es minimum temp\n",
        "  svp_min = DayMET_Img.expression('0.6108*(e**((17.27*tmin)/(tmin+237.3)))', {\n",
        "      'e': 2.71828,\n",
        "      'tmin': DayMET_Img.select('tmin').subtract(273.16)\n",
        "  }) \\\n",
        "    .rename('Saturated_Vapor_Pressure');\n",
        "  \n",
        "  # Es Maximum Temp\n",
        "  svp_max = DayMET_Img.expression('0.6108*(e**((17.27*tmax)/(tmax+237.3)))', {\n",
        "    'e': 2.71828,\n",
        "    'tmax': DayMET_Img.select('tmax').subtract(273.16)\n",
        "  }) \\\n",
        "    .rename('Saturated_Vapor_Pressure')\n",
        "  \n",
        "  # Actual Vapor Pressure from relative humidity\n",
        "  Ea = ((svp_min.multiply(GRIDMET_Img.select('rmax').divide(100)))\n",
        "    .add(svp_max.multiply(GRIDMET_Img.select('rmin').divide(100)))) \\\n",
        "    .divide(2) \\\n",
        "    .rename('Actual_Vapor_Pressure');\n",
        "\n",
        "  # Net Long-wave Radiation\n",
        "  net_lwr = DayMET_Img.expression('(sigma*((tmin**4+tmax**4)/2))*(0.34-(0.14*Kpa))*(1.35*(Rs_Rso)-0.35)', { \\\n",
        "    'Rs_Rso': 1, \\\n",
        "    'sigma': 0.0000000049, \\\n",
        "    'tmin': DayMET_Img.select('tmin'), \\\n",
        "    'tmax': DayMET_Img.select('tmax'), \\\n",
        "    'Kpa': Ea.sqrt() \\\n",
        "  }) \\\n",
        "    .rename('Net_longwave_radiation')\n",
        "\n",
        "  # Calculating Rn = R_ns - R_nl\n",
        "  # This output is in MJ/m^2/d\n",
        "  ClearSky_Rn = net_swr_Swnet.subtract(net_lwr) \\\n",
        "    .rename('Clear_Sky_Net_Radiation')\n",
        "\n",
        "  # Temperature Difference (dT) = ((Rn*Rah)/(Pa*Cp))\n",
        "  Temp_diff = DayMET_Img.expression('(Rn*Rah)/(Pa*Cp)', { \\\n",
        "    'Rn': ClearSky_Rn.divide(86.4), \\\n",
        "    'Rah': 110, \\\n",
        "    'Pa': Air_Density, \\\n",
        "    'Cp': 1.013 \\\n",
        "  }) \\\n",
        "    .rename('Temperature_Difference')\n",
        "\n",
        "  # Hot/Dry limit (Th)\n",
        "  Hot_pixel_ref = Temp_Cold.add(Temp_diff) \\\n",
        "    .rename('Hot_pixel_ref')\n",
        "\n",
        "  # Fractional Evapotranspiration\n",
        "  # ETf = (Th-Ts)/(dT) \n",
        "  # frac_evap = (Hot_pixel_ref.subtract(ARD_Img.select('LST'))) \\\n",
        "  #   .divide(Temp_diff) \\\n",
        "  #   .rename('Fractional_Evapotranspiration')\n",
        "  frac_ET = (Hot_pixel_ref.subtract(ARD_Img.select('LST'))) \\\n",
        "  .divide(Temp_diff)  \\\n",
        "  .rename('Fractional_ET')\n",
        "\n",
        "  # Map.addLayer(frac_ET, {}, 'ETf');\n",
        "\n",
        "  # ETf_mean = frac_ET.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100);\n",
        "  # print('ETf_mean', ETf_mean);\n",
        "\n",
        "  ETf_gte1d05 = frac_ET.gte(1.05).cast({'Fractional_ET':'float'});\n",
        "  ETf_lt0 = frac_ET.lt(0).cast({'Fractional_ET':'float'});\n",
        "\n",
        "  # print('ETf_gte1d05',ETf_gte1d05);\n",
        "\n",
        "  ETf_cap = ETf_gte1d05.multiply(1.05).add(ee.Image(1.0).subtract(ETf_gte1d05).multiply(frac_ET));\n",
        "  ETf_cap = ETf_lt0.multiply(0).add(ee.Image(1.0).subtract(ETf_lt0).multiply(ETf_cap));\n",
        "  # ETf_cap_mean = ETf_cap.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100);\n",
        "  # print('ETf_cap_mean', ETf_cap_mean);\n",
        "  \n",
        "  ETo_FAO = PET_value\n",
        "\n",
        "  # Actual Evapotranspiration\n",
        "  # ETa = ETf * k * ETo\n",
        "  actual_ET = DayMET_Img.expression('ETf*k*ETo', { \n",
        "    'ETf': ETf_cap,\n",
        "    'k': 1.0,\n",
        "    'ETo': ETo_FAO\n",
        "  }) \\\n",
        "    .rename('Actual_Evapotranspiration')\n",
        "  \n",
        "  mask1 = actual_ET.gte(0);\n",
        "\n",
        "  ETa_positive = actual_ET.updateMask(mask1);\n",
        "\n",
        "  # print(ETa_positive.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100))\n",
        "\n",
        "  return ETa_positive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGjqh8ltBcTy"
      },
      "source": [
        "# Export and call wrapper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3gF6N-VANBC"
      },
      "source": [
        "## Export images to GEE asset folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNTpM9jFhKFg"
      },
      "source": [
        "def export_to_asset(image, desc, assetID, TgtCounty_Bnds):\n",
        "\n",
        "  task_asset = ee.batch.Export.image.toAsset(\n",
        "    image= image,\n",
        "    description= desc,\n",
        "    assetId= assetID, # valid_dates, #date, county\n",
        "    region= TgtCounty_Bnds.first().geometry(),\n",
        "    scale= 30,\n",
        "    maxPixels= 1e13\n",
        "  )\n",
        "\n",
        "  task_asset.start()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyOogVDNAVSz"
      },
      "source": [
        "## Function to run PET and ETa functions and export function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRnGDQ_s9tT"
      },
      "source": [
        "\n",
        "def ET_retrieval_county_fn(valid_dates, TgtCounty_Bnds, TgtCounty_Name, cPara_coefArr):\n",
        "\n",
        "  for i, c_Coef in zip(valid_dates, cPara_coefArr):\n",
        "    day = ee.Date(i)\n",
        "    PET_value = potential_ET_fn(day, TgtCounty_Bnds)\n",
        "    ETa = Actual_ET_Fn(day, PET_value, TgtCounty_Bnds, c_Coef)\n",
        "\n",
        "    Landsat_folder = 'Ls5'\n",
        "    desc = TgtCounty_Name + '_' + i\n",
        "\n",
        "    assetID= 'projects/ColoradoView/ET_Seasonal_cPara/' + TgtCounty_Name + '/' + Landsat_folder + '/' + i\n",
        "    export_to_asset(ETa, desc, assetID, TgtCounty_Bnds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF8qRMgeAjqf"
      },
      "source": [
        "## Function to loop through defined counties and years and calling export function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO0HBJxRARmi"
      },
      "source": [
        "def ET_retrieval_wrapper(county_dict, in_year):\n",
        "  GEOID = copy.deepcopy(county_dict)\n",
        "\n",
        "  TgtCounty_GEOID = list(GEOID.keys())[0]\n",
        "  start_date_str = str(in_year) + '-01-01' #'2013-01-01'\n",
        "\n",
        "\n",
        "  for TgtCounty_GEOID in GEOID.keys():\n",
        "    #valid_dates, TgtCounty_Bnds, TgtCounty_Name = parameter_fn(county_dict, TgtCounty_GEOID, start_date_str)\n",
        "    valid_dates, TgtCounty_Bnds, TgtCounty_Name, cPara_coefArr = parameter_fn(GEOID, TgtCounty_GEOID, start_date_str)\n",
        "  \n",
        "    #print(\"TgtCounty_Bnds\", TgtCounty_Bnds)\n",
        "    print(\"TgtCounty_Name\", TgtCounty_Name)\n",
        "    print(\"valid_dates\", valid_dates)\n",
        "\n",
        "    ET_retrieval_county_fn(valid_dates, TgtCounty_Bnds, TgtCounty_Name, cPara_coefArr)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_RBeItEFUfi",
        "outputId": "9896929f-fcb7-45d0-a618-02ad6a787666"
      },
      "source": [
        "#@title Final call to run all functions\n",
        "\n",
        "# Dictionary of targeted counties\n",
        "county_dict = {# '08031': 'Denver',\n",
        "'08039': 'Elbert',\n",
        "# '08047': 'Gilpin',\n",
        "# '08081': 'Moffat',\n",
        "# '08095': 'Phillips',\n",
        "# '08111': 'San_Juan',\n",
        "}\n",
        "\n",
        "in_year = 2000\n",
        "ET_retrieval_wrapper(county_dict, in_year)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "TgtCounty_Name Elbert\n",
            "valid_dates ['2000-01-19', '2000-05-10', '2000-06-02', '2000-06-18', '2000-07-04', '2000-07-13', '2000-07-20', '2000-08-05', '2000-08-21', '2000-09-15', '2000-10-08', '2000-10-17', '2000-10-24', '2000-11-25']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19tx7fsBA12e"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0jcFzTBWwK9",
        "outputId": "cf6c3d6a-e2a9-45b4-a471-b7875373c902"
      },
      "source": [
        "#ARD ETa band mean\n",
        "Date_st = ee.Date('2003-05-24')\n",
        "Date_ed = Date_st.advance(1, 'day')\n",
        "\n",
        "TgtCounty_Bnds = Counties.filter(ee.Filter.eq('GEOID', '08081'))\n",
        "\n",
        "def maskLandsatARD_ET(image): \n",
        "  fillBitMask = 1\n",
        "  clearBitMask = 1 << 1\n",
        "  cloudBitMask = 1 << 5\n",
        "  # var cloudConfBit6Mask = 1 << 6;\n",
        "  # var cloudConfBit7Mask = 1 << 7;\n",
        "  # var cirrusConfBit8Mask = 1 << 8;\n",
        "  # var cirrusConfBit9Mask = 1 << 9;\n",
        "  \n",
        "  ETa_name = 'b1' #Et ... TODO\n",
        "  ETf_name = 'b2'\n",
        "  ETun_name = 'b3'\n",
        "  pixelqa_name = 'b4'\n",
        "  \n",
        "  ETqa_threshold = 1.0 #1-2 mm\n",
        "  \n",
        "  #  get the pixel QA band\n",
        "  #  pixelqa_name: 'b2'\n",
        "  pixelqa = image.select(pixelqa_name) #\n",
        "  \n",
        "  #  get the STQA band\n",
        "  # lstqa = image.select(lstqa_name)\n",
        "  # stqa_scale = ee.Number(image.get(lstqa_scale_name))\n",
        "  \n",
        "  mask = pixelqa.bitwiseAnd(fillBitMask).eq(0)  \\\n",
        "    .And(pixelqa.bitwiseAnd(clearBitMask).neq(0)) \\\n",
        "    .And(pixelqa.bitwiseAnd(cloudBitMask).eq(0))\n",
        "        #.and(pixelqa.bitwiseAnd(cloudConfBit7Mask).eq(0))\n",
        "        #.and(pixelqa.bitwiseAnd(cirrusConfBit9Mask).eq(0))\n",
        "        # .and(lstqa.multiply(stqa_scale).lt(lstqa_threshold))\n",
        "        \n",
        "        \n",
        "  #  Return the masked image (excluding the PIXELQA and STQA layers)\n",
        "  return image.updateMask(mask).select(ETa_name)\n",
        "      #  .updateMask(mask_1);// [lst_name, pixelqa_name, lstqa_name]\n",
        "\n",
        "ARD_ET = ee.Image(ARD_ET_5 \\\n",
        "  .filterDate(Date_st.format('yyyy-MM-dd'), Date_ed.format('yyyy-MM-dd')) \\\n",
        "  .filterBounds(TgtCounty_Bnds) \\\n",
        "  .map(maskLandsatARD_ET) \\\n",
        "  .mosaic())  \\\n",
        "  .multiply(0.001)  \\\n",
        "  .clip(TgtCounty_Bnds)\n",
        "\n",
        "ARD_ET_mean = ARD_ET.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100)\n",
        "print(ARD_ET_mean.getInfo())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'b1': 1.0496155825616242}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKPxhFHkSBWJ",
        "outputId": "a927d33c-592d-4187-8405-abcd0463234a"
      },
      "source": [
        "counties = ['Denver',\n",
        "            #'Gilpin',\n",
        "            'Elbert',\n",
        "            'Moffat',\n",
        "            'Phillips',\n",
        "            'San_Juan']\n",
        "for i in counties:\n",
        "  print(i)\n",
        "  # !earthengine ls projects/earthengine-legacy/assets/projects/ColoradoView/ET_Retrieval_c97/{i}/Ls5\n",
        "# import numpy as np\n",
        "# np.arange(2002, 2012, 2)\n",
        "# lat = 40.5\n",
        "# print(math.acos(math.tan(lat) * -1))\n",
        "# print(1.0e-5 * 1000)\n",
        "# print(0.409 * math.sin(2*math.pi/365 * 216 - 1.39))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Denver\n",
            "Elbert\n",
            "Moffat\n",
            "Phillips\n",
            "San_Juan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IbD-f-te1sG"
      },
      "source": [
        "#@title Loop for output values to compare with GEE\n",
        "\n",
        "# test_date = ['2018-06-11']\n",
        "# for x in test_date:\n",
        "#   test_day = ee.Date(x)\n",
        "#   PET_value = potential_ET_fn(test_day)\n",
        "#   ETa_scene = Actual_ET_Fn(test_day, PET_value)\n",
        "\n",
        "#   PET_mean = PET_value.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "#   print(PET_mean)\n",
        "#   ETa_mean = ETa_scene.reduceRegion(ee.Reducer.mean(), TgtCounty_Bnds, 100).getInfo()\n",
        "#   print(ETa_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db8ZHUIPYzge"
      },
      "source": [
        "#@title Remove files in GEE asset folder\n",
        "\n",
        "assets = [\n",
        "'projects/earthengine-legacy/assets/projects/ColoradoView/ET_Retrieval/Weld_Ls7'\n",
        "]\n",
        "\n",
        "for i in assets:\n",
        "  print(i)\n",
        "  !earthengine rm {i}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hi0QYd4MpDR"
      },
      "source": [
        "counties = [# 'Adams',\n",
        "# 'Alamosa',\n",
        "# 'Arapahoe',\n",
        "# 'Archuleta',\n",
        "# 'Baca',\n",
        "# 'Bent',\n",
        "# 'Boulder',\n",
        "# 'Broomfield',\n",
        "# 'Chaffee',\n",
        "# 'Cheyenne',\n",
        "# 'Clear_Creek',\n",
        "# 'Conejos',\n",
        "# 'Costilla',\n",
        "# 'Crowley',\n",
        "# 'Custer',\n",
        "# 'Delta',\n",
        "'Denver',\n",
        "# 'Dolores',\n",
        "# 'Douglas',\n",
        "# 'Eagle',\n",
        "# 'El_Paso',\n",
        "'Elbert',\n",
        "# 'Fremont',\n",
        "# 'Garfield',\n",
        "'Gilpin',\n",
        "# 'Grand',\n",
        "# 'Gunnison',\n",
        "# 'Hinsdale',\n",
        "# 'Huerfano',\n",
        "# 'Jackson',\n",
        "# 'Jefferson',\n",
        "# 'Kiowa',\n",
        "# 'Kit_Carson',\n",
        "# 'La_Plata',\n",
        "# 'Lake',\n",
        "# 'Larimer',\n",
        "# 'Las_Animas',\n",
        "# 'Lincoln',\n",
        "# 'Logan',\n",
        "# 'Mesa',\n",
        "# 'Mineral',\n",
        "'Moffat',\n",
        "# 'Montezuma',\n",
        "# 'Montrose',\n",
        "# 'Morgan',\n",
        "# 'Otero',\n",
        "# 'Ouray',\n",
        "# 'Park',\n",
        "'Phillips',\n",
        "# 'Pitkin',\n",
        "# 'Prowers',\n",
        "# 'Pueblo',\n",
        "# 'Rio_Blanco',\n",
        "# 'Rio_Grande',\n",
        "# 'Routt',\n",
        "# 'Saguache',\n",
        "'San_Juan',\n",
        "# 'San_Miguel',\n",
        "# 'Sedgwick',\n",
        "# 'Summit',\n",
        "# 'Teller',\n",
        "# 'Washington',\n",
        "# 'Weld',\n",
        "# 'Yuma'\n",
        "]\n",
        "\n",
        "for i in counties:\n",
        "  # print(i)\n",
        "\n",
        "  # !earthengine create folder projects/ColoradoView/ET_Retrieval/{i}/Ls5\n",
        "  # !earthengine create folder projects/ColoradoView/ET_Retrieval/{i}/Ls7\n",
        "  # !earthengine create folder projects/ColoradoView/ET_Retrieval/{i}/Ls8\n",
        "  !earthengine ls projects/earthengine-legacy/assets/projects/ColoradoView/ET_Retrieval_c97/{i}/Ls5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJUMOt9XB18v",
        "outputId": "0490086f-cc88-4911-fca6-0018c4f71e8a"
      },
      "source": [
        "CO_cPara_DF = pd.read_pickle('/gdrive/MyDrive/CO_cPara_Crop_DF.pkl')\n",
        "SeasonalCO_cPara1 = CO_cPara_DF.groupby(['Year','Season']).agg({'mean':['mean']}).reset_index()\n",
        "# SeasonalCO_cPara.groupby('Season').agg({'mean mean': ['mean']}).reset_index()\n",
        "SeasonalCO_cPara1.columns = [' '.join(col).strip() for col in SeasonalCO_cPara1.columns.values]\n",
        "SeasonalCO_cPara = SeasonalCO_cPara1.groupby('Season').agg({'mean mean': ['mean']}).reset_index()\n",
        "SeasonalCO_cPara.columns = [' '.join(col).strip() for col in SeasonalCO_cPara.columns.values]\n",
        "SeasonalCO_cPara = SeasonalCO_cPara.rename(columns={'mean mean mean':'mean'})\n",
        "SeasonalCO_cPara = SeasonalCO_cPara.set_index('Season')\n",
        "Seasonal_cPara = SeasonalCO_cPara.to_dict('dict')\n",
        "print(Seasonal_cPara)\n",
        "\n",
        "valid_ds = ['2004-02-15', '2004-05-15', '2004-01-15', '2004-11-15']\n",
        "cPara_Arr = []\n",
        "\n",
        "for x in valid_ds:\n",
        "  dt_conversion = datetime.datetime.strptime(x, '%Y-%m-%d')\n",
        "  month_date = dt_conversion.month\n",
        "  if 1 <= month_date <= 3:\n",
        "    season = 'Winter'\n",
        "    cPara = Seasonal_cPara['mean'][season]\n",
        "  elif 3 < month_date <= 6:\n",
        "    season = 'Spring'\n",
        "    cPara = Seasonal_cPara['mean'][season]\n",
        "  elif 6 < month_date <= 9:\n",
        "    season = 'Summer'\n",
        "    cPara = Seasonal_cPara['mean'][season]\n",
        "  else:\n",
        "    season = 'Fall'  \n",
        "    cPara = Seasonal_cPara['mean'][season]\n",
        "    # print(cPara)\n",
        "    # print(type(cPara))\n",
        "  cPara_Arr.append(cPara)\n",
        "\n",
        "print(cPara_Arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean': {'Fall': 0.996239931362002, 'Spring': 1.0020484104730463, 'Summer': 0.9890857449012788, 'Winter': 1.0019607117420657}}\n",
            "[1.0019607117420657, 1.0020484104730463, 1.0019607117420657, 0.996239931362002]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raHRDVYzaDYp",
        "outputId": "edde9a9f-ebcd-45b2-9215-433ce5efd9da"
      },
      "source": [
        "# county_dict = {'08001': 'Adams',\n",
        "# '08003': 'Alamosa',\n",
        "# '08005': 'Arapahoe',\n",
        "# '08007': 'Archuleta',\n",
        "# '08009': 'Baca',\n",
        "# '08011': 'Bent',\n",
        "# '08013': 'Boulder',\n",
        "# '08015': 'Chaffee',\n",
        "# '08017': 'Cheyenne',\n",
        "# '08019': 'Clear_Creek',\n",
        "# '08021': 'Conejos',\n",
        "# '08023': 'Costilla',\n",
        "# '08025': 'Crowley',\n",
        "# '08027': 'Custer',\n",
        "# '08029': 'Delta',\n",
        "# '08031': 'Denver',\n",
        "# '08033': 'Dolores',\n",
        "# '08035': 'Douglas',\n",
        "# '08037': 'Eagle',\n",
        "# '08041': 'El_Paso',\n",
        "# '08039': 'Elbert',\n",
        "# '08043': 'Fremont',\n",
        "# '08045': 'Garfield',\n",
        "# '08047': 'Gilpin',\n",
        "# '08049': 'Grand',\n",
        "# '08051': 'Gunnison',\n",
        "# '08053': 'Hinsdale',\n",
        "# '08055': 'Huerfano',\n",
        "# '08057': 'Jackson',\n",
        "# '08059': 'Jefferson',\n",
        "# '08061': 'Kiowa',\n",
        "# '08063': 'Kit_Carson',\n",
        "# '08067': 'La_Plata',\n",
        "# '08065': 'Lake',\n",
        "# '08069': 'Larimer',\n",
        "# '08071': 'Las_Animas',\n",
        "# '08073': 'Lincoln',\n",
        "# '08075': 'Logan',\n",
        "# '08077': 'Mesa',\n",
        "# '08079': 'Mineral',\n",
        "# '08081': 'Moffat',\n",
        "# '08083': 'Montezuma',\n",
        "# '08085': 'Montrose',\n",
        "# '08087': 'Morgan',\n",
        "# '08089': 'Otero',\n",
        "# '08091': 'Ouray',\n",
        "# '08093': 'Park',\n",
        "# '08095': 'Phillips',\n",
        "# '08097': 'Pitkin',\n",
        "# '08099': 'Prowers',\n",
        "# '08101': 'Pueblo',\n",
        "# '08103': 'Rio_Blanco',\n",
        "# '08105': 'Rio_Grande',\n",
        "# '08107': 'Routt',\n",
        "# '08109': 'Saguache',\n",
        "# '08111': 'San_Juan',\n",
        "# '08113': 'San_Miguel',\n",
        "# '08115': 'Sedgwick',\n",
        "# '08117': 'Summit',\n",
        "# '08119': 'Teller',\n",
        "# '08121': 'Washington',\n",
        "# '08123': 'Weld',\n",
        "# '08125': 'Yuma'\n",
        "# }\n",
        "\n",
        "# mean    1.002048\n",
        "# Name: Spring, dtype: float64\n",
        "# mean    1.001961\n",
        "# Name: Winter, dtype: float64\n",
        "# mean    0.99624\n",
        "# Name: Fall, dtype: float64\n",
        "# mean    0.989086\n",
        "# Name: Summer, dtype: float64\n",
        "\n",
        "moffat_mo_cPara = {('mean', 'mean'): {\n",
        "  1: 0.9776521179661066,\n",
        "  2: 0.9794218145513996,\n",
        "  3: 0.9912462927803484,\n",
        "  4: 1.012118814985312,\n",
        "  5: 1.0064337392680458,\n",
        "  6: 1.0034009170636713,\n",
        "  7: 0.9922805196758296,\n",
        "  8: 1.0047740820772288,\n",
        "  9: 0.9965163265707929,\n",
        "  10: 1.0117940268127896,\n",
        "  11: 0.9839506809286691,\n",
        "  12: 0.9777214143383488}}\n",
        "\n",
        "# print(type(moffat_mo_cPara))\n",
        "\n",
        "# mean_index = ('mean', 'mean')\n",
        "\n",
        "# cPara_CoefArr = []\n",
        "\n",
        "# for x in valid_dates:\n",
        "#   dt_conversion = datetime.strptime(x, '%Y-%m-%d')\n",
        "#   month_date = dt_conversion.month\n",
        "#   print(month_date)\n",
        "#   cPara_monthMean = moffat_mo_cPara[mean_index][month_date]\n",
        "#   print(cPara_monthMean)\n",
        "  # cPara_CoefArr.append(cPara_monthMean)\n",
        "  # toDO: implement test cPara for monthly mean whether it has a valid c para.\n",
        "\n",
        "# !earthengine ls projects/ColoradoView/ET_Seasonal_cPara/Phillips/Ls5\n",
        "this = np.arange(2000, 2012, 1)\n",
        "for year in this:\n",
        "  print(year)\n",
        "# print(this)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n"
          ]
        }
      ]
    }
  ]
}